{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Ranking Algorithms in PySpark\n",
        "\n",
        "**Author**: Chien-Wei WENG  \n",
        "**Program**: MSc Data Sciences and Business Analytics (DSBA)  \n",
        "**Institution**: CentraleSupélec × ESSEC Business School  \n",
        "**Course**: Scalable Data Algorithms (Fall 2025)  \n",
        "**Instructor**: Professor Mohamed Ndaoud (ESSEC Business School)\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "Implementation of two fundamental graph ranking algorithms using Apache Spark's RDD API for distributed computation on a randomly generated graph with 1,000 nodes and 8,192 edges.\n",
        "\n",
        "**Algorithms Implemented:**\n",
        "1. **PageRank** - Global importance scoring\n",
        "2. **HITS** - Hub and authority scoring\n",
        "\n",
        "**Key Technical Features:**\n",
        "- Sparse matrix representation using edge lists\n",
        "- Teleportation handling to avoid rank sinks\n",
        "- RDD caching and lineage management\n",
        "- Iterative power method with 40 iterations\n",
        "- Normalization to prevent numerical overflow"
      ],
      "metadata": {
        "id": "sFHSwwfmjs9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. PageRank Algorithm\n",
        "\n",
        "### Overview\n",
        "PageRank computes node importance based on incoming link structure.\n",
        "\n",
        "A node is important if it receives links from other important nodes.\n",
        "\n",
        "### Formula\n",
        "```\n",
        "r = (1-β)/n · 1ₙ + β·M·r\n",
        "```\n",
        "where:\n",
        "- `r`: PageRank vector\n",
        "- `β`: damping factor (0.8)\n",
        "- `M`: transition matrix\n",
        "- `n`: number of nodes (1000)\n",
        "\n",
        "### Implementation Approach\n",
        "- Initialize: r⁰ = 1/n for all nodes\n",
        "- Iterate: r^(i+1) = (1-β)/n + β·M·r^i for 40 iterations\n",
        "- Handle teleportation with probability (1-β)\n",
        "- No deadends"
      ],
      "metadata": {
        "id": "NpA7nu1N-HhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import packages"
      ],
      "metadata": {
        "id": "rc35ZTrLcncx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.7/spark-3.5.7-bin-hadoop3.tgz\n",
        "!tar zxvf spark-3.5.7-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.7-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkConf, SparkContext\n",
        "conf = SparkConf().setMaster(\"local\")\n",
        "sc = SparkContext(conf = conf)\n",
        "print(\"initialization successful!\")\n",
        "\n",
        "import numpy as np\n",
        "import random as rn\n",
        "\n",
        "seed_value=0\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RKnjhOxrTh9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "iTCzL4NB-Qwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Load graph edges"
      ],
      "metadata": {
        "id": "WOa2U8b5m0me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the graph data\n",
        "graph_file = \"graph.txt\"\n",
        "raw_data = sc.textFile(graph_file)\n",
        "\n",
        "print(\"First five lines of graph:\")\n",
        "for line in raw_data.take(5):\n",
        "  print(line)"
      ],
      "metadata": {
        "id": "BG6irT05TlQE",
        "outputId": "c39ade28-f1db-4232-fb96-a12e812251af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five lines of graph:\n",
            "1\t2\n",
            "2\t3\n",
            "3\t4\n",
            "4\t5\n",
            "5\t6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pairs (source, destinantion)\n",
        "edges = raw_data.map(lambda line: tuple(line.split()))\n",
        "\n",
        "print(f\"Total edges: {edges.count()}\\n\")\n",
        "print(\"First five edges:\")\n",
        "for edge in edges.take(5):\n",
        "  print(edge)"
      ],
      "metadata": {
        "id": "gu5FAhLpVVGj",
        "outputId": "ed1361be-5133-49e6-8dba-6b5dbdeb05fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total edges: 8192\n",
            "\n",
            "First five edges:\n",
            "('1', '2')\n",
            "('2', '3')\n",
            "('3', '4')\n",
            "('4', '5')\n",
            "('5', '6')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Compute out-degrees"
      ],
      "metadata": {
        "id": "2irJvQXGc7BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate out_degree for each node\n",
        "# Creat pairs (source, out_degree)\n",
        "\n",
        "out_degree = edges.map(lambda edge: (edge[0], 1)) \\\n",
        "          .reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "print(\"Sample out-degrees:\")\n",
        "for node, degree in out_degree.take(5):\n",
        "  print(f\"Node {node}: out-degree = {degree}\")"
      ],
      "metadata": {
        "id": "bOmeCbbgYKWw",
        "outputId": "07c969dd-4dc1-4380-d49a-668aa669be49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample out-degrees:\n",
            "Node 1: out-degree = 6\n",
            "Node 2: out-degree = 11\n",
            "Node 3: out-degree = 9\n",
            "Node 4: out-degree = 6\n",
            "Node 5: out-degree = 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join edges with out_degrees to get (source, (dest, out_degree))\n",
        "edges_with_degrees = (edges\n",
        "            .map(lambda edge: (edge[0], edge[1]))\n",
        "            .join(out_degree))"
      ],
      "metadata": {
        "id": "qFFcYdA3dFiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 Build transition matrix"
      ],
      "metadata": {
        "id": "-uN5ymQOc-8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transition matrix\n",
        "# Transform to (source, (dest, probability))\n",
        "transition_max = edges_with_degrees.map(lambda e: (e[0], (e[1][0], 1.0 / e[1][1])))\n",
        "for source, (dest, prob) in transition_max.take(5):\n",
        "  print(f\"Edge {source} -> {dest}: probability: {prob:.4f}\")"
      ],
      "metadata": {
        "id": "dyyCEEaeXYIY",
        "outputId": "0b3b957e-fa61-4a5b-d459-9043ca662bce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge 3 -> 4: probability: 0.1111\n",
            "Edge 3 -> 190: probability: 0.1111\n",
            "Edge 3 -> 545: probability: 0.1111\n",
            "Edge 3 -> 562: probability: 0.1111\n",
            "Edge 3 -> 796: probability: 0.1111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize r_0 for nodes with incoming\n",
        "num_edges = edges_with_degrees.count()\n",
        "\n",
        "r_0 = []\n",
        "for i in range(num_edges):\n",
        "  r_0.append((str(i+1), 1/1000)) # (node, rank)\n",
        "\n",
        "r_0_rdd = sc.parallelize(r_0) # rdd"
      ],
      "metadata": {
        "id": "gEWdUvIhctGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contribution to dest\n",
        "# Create pairs (source, ((dest, prob), rank))\n",
        "trainsition_2 = transition_max.join(r_0_rdd)\n",
        "\n",
        "# Convert to (dest, (source, prob, rank))\n",
        "trainsition_3 = trainsition_2.map(lambda e: (e[1][0][0], (e[0], e[1][0][1], e[1][1])))\n",
        "\n",
        "trainsition_3.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSHjzHWIleVY",
        "outputId": "8eba08d0-008d-49c6-9598-d081b5d997ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('6', ('5', 0.16666666666666666, 0.001)),\n",
              " ('931', ('5', 0.16666666666666666, 0.001)),\n",
              " ('198', ('5', 0.16666666666666666, 0.001)),\n",
              " ('394', ('5', 0.16666666666666666, 0.001)),\n",
              " ('704', ('5', 0.16666666666666666, 0.001))]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate contribution to dest\n",
        "# (dest, (prob x rank))\n",
        "contribution = trainsition_3.map(lambda e: (e[0], (e[1][1] * e[1][2]))) \\\n",
        "              .reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "for dest, rank in contribution.take(5):\n",
        "  print(f\"Edge {dest}, rank : {rank:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFLvHmX0rxlb",
        "outputId": "62c9d2b1-6854-4504-de94-10e0802b14f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge 704, rank : 0.00084702\n",
            "Edge 453, rank : 0.00086667\n",
            "Edge 761, rank : 0.00125206\n",
            "Edge 868, rank : 0.00057864\n",
            "Edge 298, rank : 0.00180087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. PageRank Implementation"
      ],
      "metadata": {
        "id": "QTHEZuvsdM77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Initialize rank vector"
      ],
      "metadata": {
        "id": "mn4VUy_1dRL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize r_1 for all nodes\n",
        "r_1 = []\n",
        "for i in range(1000):\n",
        "  r_1.append((str(i+1), None)) # (node, rank) for all nodes\n",
        "\n",
        "r_1_rdd = sc.parallelize(r_1) # rdd\n",
        "r_1_rdd.take(5)"
      ],
      "metadata": {
        "id": "v30oRz70tEtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f981d4-5dd2-4bda-9cd2-1818c4b47c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', None), ('2', None), ('3', None), ('4', None), ('5', None)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Handle teleportation"
      ],
      "metadata": {
        "id": "5bkNPt38dTXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Teleport\n",
        "beta = 0.8\n",
        "n = 1000\n",
        "teleport = (1 - beta) / n\n",
        "\n",
        "# Update contribution to nodes with incoming\n",
        "contribution_tele = contribution.mapValues(lambda contrib: teleport + beta * contrib)\n",
        "\n",
        "print(f\"Top 5 nodes before merge\")\n",
        "for node, rank in contribution_tele.takeOrdered(5, key=lambda x: -x[1]):\n",
        "  print(f\"Edge {node}, rank : {rank:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAMcYz5EUYaj",
        "outputId": "917246fa-e83b-4bf5-b8fb-82941b634a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 nodes before merge\n",
            "Edge 263, rank : 0.00187590\n",
            "Edge 502, rank : 0.00186635\n",
            "Edge 126, rank : 0.00184313\n",
            "Edge 146, rank : 0.00180125\n",
            "Edge 243, rank : 0.00178063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all nodes (without incoming + with incoming)\n",
        "# Left outer join (keeps all nodes from r_1_rdd)\n",
        "r_i_plus_1 = r_1_rdd.leftOuterJoin(contribution_tele) \\\n",
        "            .mapValues(lambda v: teleport if v[1] is None else v[1])\n",
        "\n",
        "print(f\"Top 5 nodes after merge\")\n",
        "for node, rank in r_i_plus_1.takeOrdered(5, key=lambda x: -x[1]):\n",
        "  print(f\"Edge {node}, rank : {rank:.8f}\")\n",
        "\n",
        "print(f\"\\nBottom 5 nodes after merge\")\n",
        "for node, rank in r_i_plus_1.takeOrdered(5, key=lambda x: x[1]):\n",
        "  print(f\"Edge {node}, rank : {rank:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc0Nra63dFjp",
        "outputId": "b01d7006-9db2-4743-eff7-ade6cb5f82ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 nodes after merge\n",
            "Edge 263, rank : 0.00187590\n",
            "Edge 502, rank : 0.00186635\n",
            "Edge 126, rank : 0.00184313\n",
            "Edge 146, rank : 0.00180125\n",
            "Edge 243, rank : 0.00178063\n",
            "\n",
            "Bottom 5 nodes after merge\n",
            "Edge 558, rank : 0.00032987\n",
            "Edge 93, rank : 0.00037143\n",
            "Edge 424, rank : 0.00037273\n",
            "Edge 62, rank : 0.00037273\n",
            "Edge 408, rank : 0.00042154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "print(f\"Nodes without incoming: {r_1_rdd.count()}\")\n",
        "print(f\"Nodes with incoming: {contribution_tele.count()}\")\n",
        "print(f\"Nodes for flow equation: {r_i_plus_1.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qBGEY_xia_5b",
        "outputId": "4922f0bb-4ff9-49fa-9541-6374ba8cef08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes without incoming: 1000\n",
            "Nodes with incoming: 1000\n",
            "Nodes for flow equation: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Iterative computation (40 iterations)"
      ],
      "metadata": {
        "id": "A4cN9-NCmkTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transition matrix: (source, (dest, probability))\n",
        "transition_max = edges_with_degrees.map(lambda e: (e[0], (e[1][0], 1.0 / e[1][1])))\n",
        "transition_max = transition_max.cache()\n",
        "transition_max.count()  # Force evaluation and cache it\n",
        "\n",
        "# Initialize r_0 for nodes with incoming\n",
        "num_edges = edges_with_degrees.count()\n",
        "\n",
        "r_0 = []\n",
        "for i in range(num_edges):\n",
        "  r_0.append((str(i+1), 1/1000)) # (node, rank)\n",
        "\n",
        "r_0_rdd = sc.parallelize(r_0) # rdd\n",
        "\n",
        "# Initialize r_1 for all nodes\n",
        "r_1 = []\n",
        "for i in range(1000):\n",
        "  r_1.append((str(i+1), None)) # (node, rank) for all nodes\n",
        "\n",
        "r_1_rdd = sc.parallelize(r_1) # rdd\n",
        "\n",
        "\n",
        "# Initialize teleport\n",
        "beta = 0.8\n",
        "n = 1000\n",
        "teleport = (1 - beta) / n"
      ],
      "metadata": {
        "id": "G3JAq9v_6hX6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline for 40 iterations\n",
        "\n",
        "# Start with r_0\n",
        "current_rank = r_0_rdd\n",
        "\n",
        "# Iterate 40 times\n",
        "for iteration in range(40):\n",
        "  # 1. Join transition_matrix with current_rank: (source, ((dest, prob), rank))\n",
        "  transition_2 = transition_max.join(current_rank)\n",
        "  # 2. Convert to (dest, (source, prob, rank))\n",
        "  transition_3 = transition_2.map(lambda e: (e[1][0][0], (e[0], e[1][0][1], e[1][1])))\n",
        "  # 3. Compute contribution (M · r): (dest, (prob x rank))\n",
        "  contribution = transition_3.map(lambda e: (e[0], (e[1][1] * e[1][2]))) \\\n",
        "              .reduceByKey(lambda x, y: x + y)\n",
        "  # 4. Add teleportation: teleport + beta * contribution\n",
        "  contribution_tele = contribution.mapValues(lambda contrib: teleport + beta * contrib)\n",
        "  # 5. Handle nodes without incoming edges (leftOuterJoin)\n",
        "  r_i_plus_1 = r_1_rdd.leftOuterJoin(contribution_tele) \\\n",
        "            .mapValues(lambda v: teleport if v[1] is None else v[1])\n",
        "\n",
        "  # Cache new result and unpersist old\n",
        "  r_i_plus_1.cache()\n",
        "  r_i_plus_1.count()  # Force evaluation\n",
        "  current_rank.unpersist()\n",
        "\n",
        "  # 6. Update current_rank for next iteration\n",
        "  current_rank = r_i_plus_1  # Result becomes input for next iteration\n",
        "\n",
        "  if iteration % 10 == 0:\n",
        "    print(f\"Iteration {iteration} complete\")"
      ],
      "metadata": {
        "id": "Up8P8otRfy27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c635df-f40c-42dc-a4f9-19f5b0152058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 complete\n",
            "Iteration 10 complete\n",
            "Iteration 20 complete\n",
            "Iteration 30 complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. PageRank Results"
      ],
      "metadata": {
        "id": "i4hC1Jekdbsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 Top 5 ranked nodes"
      ],
      "metadata": {
        "id": "GgQuspJwddg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Top 5 nodes after 40 iterations\")\n",
        "for node, rank in current_rank.takeOrdered(5, key=lambda x: -x[1]):\n",
        "  print(f\"Edge {node}, rank : {rank:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KRZYQJRtnlr",
        "outputId": "92c734d1-9bc5-4d16-aad4-10a222970dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 nodes after 40 iterations\n",
            "Edge 263, rank : 0.00201742\n",
            "Edge 537, rank : 0.00194384\n",
            "Edge 965, rank : 0.00189436\n",
            "Edge 243, rank : 0.00184955\n",
            "Edge 187, rank : 0.00183004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 Bottom 5 ranked nodes"
      ],
      "metadata": {
        "id": "b_cEIuvmdfZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Bottom 5 nodes after 40 iterations\")\n",
        "for node, rank in current_rank.takeOrdered(5, key=lambda x: x[1]):\n",
        "  print(f\"Edge {node}, rank : {rank:.8f}\")"
      ],
      "metadata": {
        "id": "2iBuwlb_tunt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7731cc-8803-4eae-9400-7cf71f280bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bottom 5 nodes after 40 iterations\n",
            "Edge 558, rank : 0.00032955\n",
            "Edge 93, rank : 0.00035143\n",
            "Edge 424, rank : 0.00035484\n",
            "Edge 62, rank : 0.00036131\n",
            "Edge 408, rank : 0.00038759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. HITS Algorithm\n",
        "\n",
        "### Overview\n",
        "HITS distinguishes between two complementary types of important pages:\n",
        "- **Hubs**: Pages that link to many authoritative pages\n",
        "- **Authorities**: Pages that receive links from many good hubs\n",
        "\n",
        "### Formulas\n",
        "```\n",
        "h = λL·a   (hub score from authority of outlinks)\n",
        "a = μL^T·h (authority score from hub quality of inlinks)\n",
        "```\n",
        "where:\n",
        "- `h`: hubbiness vector\n",
        "- `a`: authority vector\n",
        "- `L`: link matrix (L_ij = 1 if i→j)\n",
        "- `λ, μ`: scaling factors (both = 1)\n",
        "\n",
        "### Implementation Approach\n",
        "- Initialize: h⁰ = all 1's\n",
        "- Iterate 40 times:\n",
        "  1. Compute a = μL^T·h, normalize to max=1\n",
        "  2. Compute h = λL·a, normalize to max=1\n",
        "- Mutual reinforcement: hubs ↔ authorities"
      ],
      "metadata": {
        "id": "0aD4cdM8e8Js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Link Matrix Construction"
      ],
      "metadata": {
        "id": "Hv4llrRw852x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse the same edges from PageRank\n",
        "# L has structure: (source, dest) where Lij = 1 if i→j\n",
        "\n",
        "# Load the graph data\n",
        "graph_file = \"graph.txt\"\n",
        "raw_data = sc.textFile(graph_file) # rdd\n",
        "\n",
        "# Create pairs (source, destinantion)\n",
        "L = raw_data.map(lambda line: tuple(line.split()))\n",
        "\n",
        "print(f\"Total links: {L.count()}\\n\")\n",
        "print(f\"First five links: \\n{L.take(5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygW_Nnb-pMMr",
        "outputId": "482ec5a1-6f6b-4125-98a8-0c87718a59ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total links: 8192\n",
            "\n",
            "First five links: \n",
            "[('1', '2'), ('2', '3'), ('3', '4'), ('4', '5'), ('5', '6')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Vectors"
      ],
      "metadata": {
        "id": "khEJ0iZqgF0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1000\n",
        "Lambda = 1 # Scaling factor for hubs\n",
        "mu = 1 # Scaling factor for authorities\n",
        "\n",
        "# Initialize h with all 1's (hubbiness vector)\n",
        "h_vector = []\n",
        "for i in range(n):\n",
        "  h_vector.append((i, 1)) # (node, initial_hub_score)\n",
        "\n",
        "h = sc.parallelize(h_vector) # rdd"
      ],
      "metadata": {
        "id": "D-kp8ivLnBia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Compute authority vector: $a = µL^Th$ (column $j$ as row × vector):\n",
        "- Result: sum of $h[i]$ for all $i$ that point to $j$"
      ],
      "metadata": {
        "id": "9LeY_JdgnATU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Join L with h on source\n",
        "L_with_h = L.map(lambda edge: (int(edge[0]), int(edge[1]))) \\\n",
        "        .join(h) # (source, (dest, h_value))\n",
        "\n",
        "# Map to (dest, h_value) - contribution to destination's authority\n",
        "contributions_to_dest = L_with_h.map(lambda x: (x[1][0], x[1][1])) # (dest, h_value)\n",
        "\n",
        "# Sum contribution per destination\n",
        "a_unnormalized = contributions_to_dest.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "# Scale by mu and normalize\n",
        "max_a = a_unnormalized.map(lambda x: x[1]).max()\n",
        "a = a_unnormalized.mapValues(lambda v: mu * v / max_a)"
      ],
      "metadata": {
        "id": "Z5PDrTbwz53c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Compute hubbiness vector: $h = λLa$ (row $i$ × column vector):\n",
        "- Result: sum of $a[j]$ for all $j$ that $i$ points to"
      ],
      "metadata": {
        "id": "65xa7fiMmggm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Join L with an on destination\n",
        "L_with_a = L.map(lambda edge: (int(edge[1]), int(edge[0]))) \\\n",
        "        .join(a) # (dest, (source, a_value))\n",
        "\n",
        "# Map to (source, a_value) - contribution to source's hub\n",
        "contributions_to_source = L_with_a.map(lambda x: (x[1][0], x[1][1])) # (source, a_value)\n",
        "\n",
        "# Sum contribution per source\n",
        "h_unnormalized = contributions_to_source.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "# Scale by Lambda and normalize\n",
        "max_h = h_unnormalized.map(lambda x: x[1]).max()\n",
        "h = h_unnormalized.mapValues(lambda v: Lambda * v / max_h)"
      ],
      "metadata": {
        "id": "5uZBguuSoas5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterative Computation (40 iterations)"
      ],
      "metadata": {
        "id": "zfK_VJ3d873z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline for 40 iterations\n",
        "L = L.cache()\n",
        "L.count()\n",
        "\n",
        "# Start with all 1's\n",
        "current_h = h\n",
        "current_a = None\n",
        "\n",
        "# Iterate 40 times\n",
        "for iteration in range(40):\n",
        "  # Step 1: Compute authority a = μL^T·h\n",
        "  # L^T·h means: for each dest, sum h values of sources pointing to it\n",
        "  L_with_h = L.map(lambda edge: (int(edge[0]), int(edge[1]))) \\\n",
        "        .join(current_h) # (source, (dest, h_value))\n",
        "\n",
        "  contributions_to_dest = L_with_h.map(lambda x: (x[1][0], x[1][1])) # (dest, h_value)\n",
        "  a_unnormalized = contributions_to_dest.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "  # Normalize: max value = 1\n",
        "  max_a = a_unnormalized.map(lambda x: x[1]).max()\n",
        "  current_a = a_unnormalized.mapValues(lambda v: mu * v / max_a)\n",
        "\n",
        "  # Cache new result\n",
        "  current_a.cache()\n",
        "  current_a.count()\n",
        "\n",
        "\n",
        "  # Step 2: Compute hubbiness h = λL·a\n",
        "  # L·a means: for each source, sum a values of dests it points to\n",
        "  L_with_a = L.map(lambda edge: (int(edge[1]), int(edge[0]))) \\\n",
        "          .join(current_a)\n",
        "\n",
        "  contributions_to_source = L_with_a.map(lambda x: (x[1][0], x[1][1])) # (source, a_value)\n",
        "  h_unnormalized = contributions_to_source.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "  # Normalize: max value = 1\n",
        "  max_h = h_unnormalized.map(lambda x: x[1]).max()\n",
        "  new_h = h_unnormalized.mapValues(lambda v: Lambda * v / max_h)\n",
        "  new_h.cache()\n",
        "  new_h.count()\n",
        "\n",
        "\n",
        "  # Unpersist old values\n",
        "  if current_h:\n",
        "    current_h.unpersist()\n",
        "  current_h = new_h\n",
        "\n",
        "  if iteration % 10 == 0:\n",
        "    print(f\"Iteration {iteration} complete\")"
      ],
      "metadata": {
        "id": "YZ_MtRvkuBOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7f935880-d8ca-440e-da56-aa666fb9eb92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 complete\n",
            "Iteration 10 complete\n",
            "Iteration 20 complete\n",
            "Iteration 30 complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HITS Results"
      ],
      "metadata": {
        "id": "QPR0h_jUl_Lr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Top 5 hubs\n",
        "- Bottom 5 hubs"
      ],
      "metadata": {
        "id": "ZnDwBjPvmHMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Top 5 nodes with the highest hubbiness score\")\n",
        "for node, h in current_h.takeOrdered(5, key=lambda x: -x[1]):\n",
        "  print(f\"Edge {node}, hubbiness score : {h:.8f}\")\n",
        "\n",
        "print(f\"Bottom 5 nodes with the lowest hubbiness score\")\n",
        "for node, h in current_h.takeOrdered(5, key=lambda x: x[1]):\n",
        "  print(f\"Edge {node}, hubbiness score : {h:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hWOpV5L-abF",
        "outputId": "a7f37423-dc54-46c1-d4dd-50c374ba17f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 nodes with the highest hubbiness score\n",
            "Edge 840, hubbiness score : 1.00000000\n",
            "Edge 155, hubbiness score : 0.87581037\n",
            "Edge 234, hubbiness score : 0.83653755\n",
            "Edge 389, hubbiness score : 0.79747129\n",
            "Edge 472, hubbiness score : 0.79615526\n",
            "Bottom 5 nodes with the lowest hubbiness score\n",
            "Edge 23, hubbiness score : 0.03903892\n",
            "Edge 835, hubbiness score : 0.05302275\n",
            "Edge 141, hubbiness score : 0.05935309\n",
            "Edge 539, hubbiness score : 0.06309816\n",
            "Edge 889, hubbiness score : 0.07042761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Top 5 authorities\n",
        "- Bottom 5 authorities"
      ],
      "metadata": {
        "id": "BsDGBi6WmMNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Top 5 nodes with the highest authority score\")\n",
        "for node, a in current_a.takeOrdered(5, key=lambda x: -x[1]):\n",
        "  print(f\"Edge {node}, hubbiness score : {a:.8f}\")\n",
        "\n",
        "print(f\"Bottom 5 nodes with the lowest authority score\")\n",
        "for node, a in current_a.takeOrdered(5, key=lambda x: x[1]):\n",
        "  print(f\"Edge {node}, hubbiness score : {a:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHDjEHMu_Ytb",
        "outputId": "70342542-6ad1-4c23-fef6-8062e9a5141a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 nodes with the highest authority score\n",
            "Edge 893, hubbiness score : 1.00000000\n",
            "Edge 16, hubbiness score : 0.96776625\n",
            "Edge 799, hubbiness score : 0.95135153\n",
            "Edge 146, hubbiness score : 0.94164366\n",
            "Edge 473, hubbiness score : 0.90610856\n",
            "Bottom 5 nodes with the lowest authority score\n",
            "Edge 19, hubbiness score : 0.05837246\n",
            "Edge 135, hubbiness score : 0.06686172\n",
            "Edge 462, hubbiness score : 0.07511939\n",
            "Edge 24, hubbiness score : 0.08360036\n",
            "Edge 910, hubbiness score : 0.08543487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison: PageRank vs HITS"
      ],
      "metadata": {
        "id": "ybw8c8ONiOJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm Differences\n",
        "\n",
        "| Aspect | PageRank | HITS |\n",
        "|--------|----------|------|\n",
        "| **Output** | Single importance score | Hub + Authority scores |\n",
        "| **Top Node** | 263 (0.00201) | Hub: 840, Authority: 893 |\n",
        "| **Concept** | Global importance via random walk | Mutual reinforcement of roles |\n",
        "| **Use Case** | Overall page importance | Distinguishing sources vs destinations |\n",
        "| **Computation** | 1 vector update per iteration | 2 vector updates per iteration |\n",
        "| **Performance** | Faster | ~2× slower |"
      ],
      "metadata": {
        "id": "KU1V7eYcmrxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Insight\n",
        "\n",
        "Different nodes rank highly in different algorithms, showing they measure complementary aspects:\n",
        "- **PageRank**: Global importance (who should I visit?)\n",
        "- **HITS Hubs**: Quality as connector (who knows good resources?)\n",
        "- **HITS Authorities**: Quality as destination (who is the expert?)"
      ],
      "metadata": {
        "id": "n4PBeZhfmtLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Learning Outcomes"
      ],
      "metadata": {
        "id": "vKfF3UcUiw24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distributed Systems Concepts\n",
        "- MapReduce paradigm (map, reduce, join operations)\n",
        "- Trade-offs between materialization and recomputation\n",
        "- Data locality and partitioning importance"
      ],
      "metadata": {
        "id": "nOU97a3CmeGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithmic Insights\n",
        "- Why teleportation is crucial for PageRank convergence\n",
        "- How sparse matrix representations save memory\n",
        "- Mutually reinforcing relationships in HITS\n",
        "- Normalization prevents numerical overflow"
      ],
      "metadata": {
        "id": "ulZnqxyQmf7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Optimization\n",
        "- Strategic use of `.cache()` and `.persist()`\n",
        "- RDD lineage management to avoid deep dependencies\n",
        "- Avoiding shuffle operations where possible"
      ],
      "metadata": {
        "id": "c5qdoPSzmh-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Potential Extensions\n",
        "\n",
        "1. **Personalized PageRank**: Bias teleportation toward specific nodes\n",
        "2. **Convergence Detection**: Stop when changes fall below threshold\n",
        "3. **Visualization**: Graph with node sizes proportional to scores\n",
        "4. **Scalability Testing**: Benchmark on 10K, 100K, 1M node graphs\n",
        "5. **Topic-Sensitive HITS**: Weight edges by content similarity"
      ],
      "metadata": {
        "id": "Y7mBjAJNmkBw"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}